<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Deep Image Matting | Kshitij Agrawal - AI Scientist</title><meta name=keywords content="image matting,background removal,deep image matting"><meta name=description content="What is Image Matting Natural image matting is a fundamental computer vision task, which aims to predict an alpha matte of the foreground object from a given image. An image can be represented by a linear combination of foreground and background, with a blending of a parameter alpha. Mathematically, image matting is formulated as:
Ii = αiFi + (1 − αi)Bi ,
where Ii, αi, Fi and Bi are observed colour value, alpha value, foreground value and background value of pixel i, respectively."><meta name=author content="Kshitij Agrawal"><link rel=canonical href=https://kshitijagrwl.com/posts/image-matting-background-removal/><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://kshitijagrwl.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kshitijagrwl.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kshitijagrwl.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kshitijagrwl.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kshitijagrwl.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-E699L51FMJ"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-E699L51FMJ",{anonymize_ip:!1})}</script><meta property="og:title" content="Deep Image Matting"><meta property="og:description" content="What is Image Matting Natural image matting is a fundamental computer vision task, which aims to predict an alpha matte of the foreground object from a given image. An image can be represented by a linear combination of foreground and background, with a blending of a parameter alpha. Mathematically, image matting is formulated as:
Ii = αiFi + (1 − αi)Bi ,
where Ii, αi, Fi and Bi are observed colour value, alpha value, foreground value and background value of pixel i, respectively."><meta property="og:type" content="article"><meta property="og:url" content="https://kshitijagrwl.com/posts/image-matting-background-removal/"><meta property="og:image" content="https://kshitijagrwl.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-23T01:51:31+05:30"><meta property="article:modified_time" content="2023-07-23T01:51:31+05:30"><meta property="og:site_name" content="Kshitij Agrawal"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kshitijagrwl.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Deep Image Matting"><meta name=twitter:description content="What is Image Matting Natural image matting is a fundamental computer vision task, which aims to predict an alpha matte of the foreground object from a given image. An image can be represented by a linear combination of foreground and background, with a blending of a parameter alpha. Mathematically, image matting is formulated as:
Ii = αiFi + (1 − αi)Bi ,
where Ii, αi, Fi and Bi are observed colour value, alpha value, foreground value and background value of pixel i, respectively."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://kshitijagrwl.com/posts/"},{"@type":"ListItem","position":2,"name":"Deep Image Matting","item":"https://kshitijagrwl.com/posts/image-matting-background-removal/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deep Image Matting","name":"Deep Image Matting","description":"What is Image Matting Natural image matting is a fundamental computer vision task, which aims to predict an alpha matte of the foreground object from a given image. An image can be represented by a linear combination of foreground and background, with a blending of a parameter alpha. Mathematically, image matting is formulated as:\nIi = αiFi + (1 − αi)Bi ,\nwhere Ii, αi, Fi and Bi are observed colour value, alpha value, foreground value and background value of pixel i, respectively.","keywords":["image matting","background removal","deep image matting"],"articleBody":"What is Image Matting Natural image matting is a fundamental computer vision task, which aims to predict an alpha matte of the foreground object from a given image. An image can be represented by a linear combination of foreground and background, with a blending of a parameter alpha. Mathematically, image matting is formulated as:\nIi = αiFi + (1 − αi)Bi ,\nwhere Ii, αi, Fi and Bi are observed colour value, alpha value, foreground value and background value of pixel i, respectively.\nThe matting task estimates the value of alpha to extract a foreground effectively. This is an ill posed problem with only three known variables and seven unknowns. An additional challenge arises as there is no consistent definition of foreground in a image and it is a highly subjective factor, dependent on the scene.\nWhile being similar to semantic segmentation, matting, generates a more natural and delicate foreground than semantic segmentation. It plays a central role in downstream tasks like image editing, advertising, background removal and background replacement. In video production, it is common to remove the background for visual effects and apply a new background in its place. Typically the alpha matte is computed using a blue (or green) background for easier segmentation.\nMatting methods have evolved to handle such complex scenarios by providing auxiliary inputs like trimap, depth or scribbles to guide the matting process. More recently, some methods have focused on completely automatic methods to extract the relevant alpha matte.\nKey Terms Trimap - Natural matting algorithms often require a user generated segmentation to identify background, foreground, and unknown regions. This segmentation is called a trimap. In general, trimaps must be drawn by hand, either for each frame, or at keyframes. It guides the network to focus on refining only the unknown regions to generate a fine grained alpha matte.\nEvaluation -\nSAD MSE GRAD CONN Types of Image matting Pre deep learning Conventional matting methods relied on assumptions such as local smoothness (color sampling) or structure affinity (affinity matrix). Due to the nature of such low-level color cues, it was difficult to handle the large amount of variation in complex images. Deep matting methods evolved to overcome this dilema.\nDL based we will focus on this in this article\nAutomatic Guided Deep Architectures Single Stage - DIM FBA Matting\nDual stage SHM\nMultibranch architectures PPmatting DIS\nTransformers!\nMattformer First use of transformer for matting task VITmatte Introduced a lightweight decoder branch that is inspired from VIT detector. They reduce the computations from 18M to 2.5M in the decoder Also Conclusion Methods with auxilliary guidance are still superior Transforms with attention mechanism are closing the gap and solving for global vs local consistency References List of matting resources - awesome-image-matting ","wordCount":"455","inLanguage":"en","datePublished":"2023-07-23T01:51:31+05:30","dateModified":"2023-07-23T01:51:31+05:30","author":{"@type":"Person","name":"Kshitij Agrawal"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://kshitijagrwl.com/posts/image-matting-background-removal/"},"publisher":{"@type":"Organization","name":"Kshitij Agrawal - AI Scientist","logo":{"@type":"ImageObject","url":"https://kshitijagrwl.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kshitijagrwl.com/ accesskey=h title="Home (Alt + H)"><img src=https://kshitijagrwl.com/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kshitijagrwl.com/tags/ title=tags><span>tags</span></a></li><li><a href=https://kshitijagrwl.com/about/ title=about><span>about</span></a></li><li><a href=https://kshitijagrwl.com/consulting/ title=consulting><span>consulting</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Deep Image Matting</h1><div class=post-meta><span title='2023-07-23 01:51:31 +0530 IST'>23 July 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;455 words&nbsp;·&nbsp;Kshitij Agrawal</div></header><div class=post-content><h2 id=what-is-image-matting>What is Image Matting<a hidden class=anchor aria-hidden=true href=#what-is-image-matting>#</a></h2><p>Natural <strong>image matting</strong> is a fundamental computer vision task, which aims to predict an alpha matte of the foreground object from a given image. An image can be represented by a linear combination of foreground and background, with a blending of a parameter alpha. Mathematically, image matting is formulated as:</p><p>Ii = αiFi + (1 − αi)Bi ,</p><p>where Ii, αi, Fi and Bi are observed colour value, alpha value, foreground value and background value of pixel i, respectively.</p><p>The matting task estimates the value of alpha to extract a foreground effectively. This is an ill posed problem with only three known variables and seven unknowns. An additional challenge arises as there is no consistent definition of foreground in a image and it is a highly subjective factor, dependent on the scene.</p><p>While being similar to semantic segmentation, matting, generates a more natural and delicate foreground than semantic segmentation. It plays a central role in downstream tasks like image editing, advertising, background removal and background replacement. In video production, it is common to remove the background for visual effects and apply a new background in its place. Typically the alpha matte is computed using a blue (or green) background for easier segmentation.</p><p>Matting methods have evolved to handle such complex scenarios by providing auxiliary inputs like trimap, depth or scribbles to guide the matting process. More recently, some methods have focused on completely automatic methods to extract the relevant alpha matte.</p><h2 id=key-terms>Key Terms<a hidden class=anchor aria-hidden=true href=#key-terms>#</a></h2><p>Trimap - Natural matting algorithms often require a user generated segmentation to identify background, foreground, and unknown regions. This segmentation is called a trimap. In general, trimaps must be drawn by hand, either for each frame, or at keyframes. It guides the network to focus on refining only the unknown regions to generate a fine grained alpha matte.</p><p>Evaluation -</p><ol><li>SAD</li><li>MSE</li><li>GRAD</li><li>CONN</li></ol><h2 id=types-of-image-matting>Types of Image matting<a hidden class=anchor aria-hidden=true href=#types-of-image-matting>#</a></h2><ol><li><p>Pre deep learning
Conventional matting methods relied on assumptions such as local smoothness (color sampling) or structure affinity (affinity matrix). Due to the nature of such low-level color cues, it was difficult to handle the large amount of variation in complex images. Deep matting methods evolved to overcome this dilema.</p></li><li><p>DL based
we will focus on this in this article</p><ol><li>Automatic</li><li>Guided</li></ol></li></ol><h2 id=deep-architectures>Deep Architectures<a hidden class=anchor aria-hidden=true href=#deep-architectures>#</a></h2><ol><li><p>Single Stage -
DIM
FBA Matting</p></li><li><p>Dual stage
SHM</p></li><li><p>Multibranch architectures
PPmatting
DIS</p></li><li><p>Transformers!</p><ol><li>Mattformer
First use of transformer for matting task</li><li>VITmatte
Introduced a lightweight decoder branch that is inspired from VIT detector. They reduce the computations from 18M to 2.5M in the decoder
Also</li></ol></li></ol><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><ol><li>Methods with auxilliary guidance are still superior</li><li>Transforms with attention mechanism are closing the gap and solving for global vs local consistency</li></ol><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li>List of matting resources - <a href=https://github.com/kshitijagrwl/awesome-image-matting>awesome-image-matting</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://kshitijagrwl.com/tags/image-matting/>image matting</a></li><li><a href=https://kshitijagrwl.com/tags/background-removal/>background removal</a></li><li><a href=https://kshitijagrwl.com/tags/deep-image-matting/>deep image matting</a></li></ul><nav class=paginav><a class=next href=https://kshitijagrwl.com/posts/on-metric-learning/><span class=title>Next »</span><br><span>On Deep Metric Learning</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://kshitijagrwl.com/>Kshitij Agrawal - AI Scientist</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>